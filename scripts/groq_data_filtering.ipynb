{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/OMIEC_NEUROMORPHIC.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "df_with_responses = pd.DataFrame()\n",
    "\n",
    "total = len(full_df['Abstract'])\n",
    "total_time = 0\n",
    "\n",
    "for index, row in full_df.iterrows():\n",
    "    start_time = time.time()\n",
    "    print(index, 'of', total, 'remaining estimated time', (total-index)*(total_time/(index+1)))\n",
    "    payload = { \n",
    "        'prompt': \"\"\"{\n",
    "        'systemPrompt': 'RolePlay as a bot seeking for catalysts', \n",
    "        'user': \"For the text I will input next, output only the catalyst materials used for the oxygen reduction reaction. Do not output precursors, electrolytes, and other kinds of materials, only the catalyst. The output must be only the catalyst material names separated by semicolons. Do not repeat the material name more than once. If no catalyst was found, output 'None'\",\n",
    "        'Assistant': 'Hello, I will tell the catalysts of any text you input next',\n",
    "        'user_text':\"\"\" + row['Abstract'] + \"}\",\n",
    "        \"temperature\":0.75,\n",
    "        \"topP\":0.9,\n",
    "        \"maxTokens\": 1000\n",
    "    }\n",
    "    #print(payload)\n",
    "    response = requests.post('https://fumes-api.onrender.com/llama3', json=payload, stream=True)\n",
    "    filtered_response = response.text.replace(' YOU CAN BUY ME COFFE! https://buymeacoffee.com/mygx', '')\n",
    "    print(filtered_response)\n",
    "    row['response'] = filtered_response\n",
    "    df_with_responses = df_with_responses.append(row)\n",
    "    time.sleep(2.5)\n",
    "    total_time = total_time + time.time() - start_time\n",
    "    print('Time for this loop:', time.time() - start_time, 'average loop time:', (total_time/(index+1)))\n",
    "    #for chunk in response.iter_content(chunk_size=1024):  \n",
    "    #    if chunk:\n",
    "    #        print(chunk.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "df_with_responses = pd.DataFrame()\n",
    "\n",
    "total = len(df['Abstract'])\n",
    "total_time = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    start_time = time.time()\n",
    "    print(index, 'of', total, 'remaining estimated time', (total-index)*(total_time/(index+1)))\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"RolePlay as a bot seeking for polymers that are used in neuromorphic devices\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"For the text I will input next, output only polymers used for neuromorphic devices. Do not output other types of polymers, and other kinds of materials, only the polymers. The output must be only the polymer material names separated by semicolons. Do not repeat the polymer name more than once. If no polymer was found, output 'None'\\\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Hello, I will tell the polymers that are used in neuromorphic devices of any text you input next\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\\\"\\\" + row['Abstract'] + \"\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbeneti-LNLS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
